Monday 15/6/2020
- Setup and configured dev environment: VSCode on Windows connected to remote Debian WSL, configured C++ Intellisense to use g++ and boost libraries
- Figured out how to include boost and compile with g++
- Installed CMake and Native Debug VSCode plugins
- todo: test CMake compilation, test boost filesystem code, read C++ project structure webpages (see saved Firefox session 15/6)

Tues 16/6/2020
- Made decision to use std::filesystem from C++17 preferably over boost::filesystem - standard lib vs 3rd party include
- Read C++ project structure (directory layout conventions) webpages (see saved Firefox session 15/6)

Wed 17/6/2020
- Altered directory structure to follow std form (/include, /src, /build directories)
- Configured CMakeLists.txt and correct building of project with cmake, including correct linking of std::filesystem
- Built and tested inotify-cpp library to watch a directory

Thur 18/6/2020
- Read through code of fswatch library, providing multiplatform filesystem watches - uses inotify and stat() on Linux
- Determined inotify alone is insufficient - cannot determine file changes if service is not running e.g. machine off, program crash
    - Still need a local database/log of local files, possibly though stat() or more likely std::filesystem.
    - Polling of large directories and many files will be slow. Ideal solution is inotify when service is running, with semi-regular file index polling/updates for best efficiency.
- Basic getting of file attributes with std::filesystem
    - Determine which file attributes are required
- Determine database system - sqlite? slow lookups when reading from file? hashmaps in memory, but then need to serialise to save when service not running
    - SQLite    - unencrypted db file on host, encrypt as a regular backed up file and send to host for backup
                - can be faster than I/O, small size, ACID transactions, well tested
                - SQL query language
    - file      - requires serialisation, constant I/O or bucketing of transactions
                - fast for a relatively small number of items
                - possible to do this with Boost MultiIndex MRU object cache or Boost lib serialisation

Fri 19/6/2020
- SQLite file index database connection made and libraries linked from code
- Separate FileIndex class prototype for index functions/capability
- todo: File integrity checks with hashes - compute before upload, and after, benchmark various hashing algos e.g. md5, sha-1, sha-256
    - http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=A91D1D99A03C47E5E4E73AB012A65D3B?doi=10.1.1.657.9552&rep=rep1&type=pdf
- desired feature/improvement: inotify running in addition to regular file system polling and indexdb updates

Mon 22/6/2020
- Created abstracted DB class to handle DB functions (e.g. open/close db, execute SQL code with error handling), new main class "enclone" to tie together all other classes
- enclone class includes vector of shared_pts to Watch* objects, allowing multiple watch directories to be added
    - todo: regularly save this in SQLite db for persistance on crash/restart, and restore from db on start
- DB structure - 2 tables created and initialised from code
    - WatchDirs - path
    - FileIndex - IDX/filename/path/mod time/size/file hash

Tue 23/6/2020
- Changed Watch class to have single instance with a vector of watched directories/files inside
- Added recursive params to recursively add directories to Watch if bool recursive is true
- Researching how to develop into a linux daemon/service (encloned), ability to add watch files/directories from cmd line - need interprocess communcation (IPC)
    - use new style systemd daemon rather than old SysV daemons - guarantees daemon starts with a clean context, avoids issues with lost file descriptors when a process is forked the old way
    - see https://manpages.debian.org/testing/systemd/daemon.7.en.html
    - IPC:
        - 1. run binary via systemd and have it load a config file or from db for file watches etc, wrapper program can write to config/db however this would mean constant reloading of config files needs to be done (SIGHUP signal to systemd tells it to reload config)
            - issue with file locks with SQLite - need to ensure locks are respected/retry transactions - daemon can only read db if it notices mod time has changed
        - 2. alternatively open a socket to local process to allow control via another client config application - also see above link and sd_listen_fds(3) and sd-daemon(3)
            - "unix domain", local socket required - possible via Boost.Asio
            - allows possibility to extend to inter-computer communcation i.e. remote management
            - preferred option
        - 3. named pipes can share information between processes
            - should be fairly simple, inbuilt to linux, only one way communcation
        - 4. Boost.Interprocess - allows shared memory/messages between processes, but unecessary, do not require shared objects etc, only simple messages
    - for development/testing/debugging, seems easier to run daemon in foreground, then amend code later to run in systemd e.g. have systemd create and activate sockets as recommended, rather than manually creating them
- Include Boost.Asio and created new Socket.h classes - code compiles and runs but is not async so blocks further code from running
- todo: finish watch directory and files db, produce MVP - can implement sockets to control later

Wed 24/6/2020
- Populated watchFiles with files to watch and their attributes and abstracted and tidied up elements of the Watch::addWatch() method
- Changed vectors for watchFiles and watchDir into unordered_map, to avoid duplicate paths being added
    - watchDirs key is path, value contains flag for if watched directory is recursively watched
    - watchFiles key is path, value contains the last mod time of the file
    - added check/error message for duplicate file/directory when attempting to add a watch
- Added main execLoop to scan for:
    1. changes in files (change in file mod time)
    2. file or directory deletion (file/directory does not exist)
    3. new file/directory is added (if the watched directory recursive flag is true, new directory and contained files added)
- todo: research std::thread and std::jthread - ideally need to run execLoop is separate thread, and Socket in a separate thread to avoid blocking


Thur 25/6/2020
- Added path check for file/directory existing before adding
- Ammended fileIndex to store last modified time as std::time_t (unix time as integer) to enable storage in DB
- Dump dirIndex and fileIndex to DB, unique specifier on path columns to avoid duplicates
- Added a "bucket" for SQL commands in Watch - stringstream sqlQueue will keep appending SQL queries to be executed at once in a bucket similar to Nagles Algorithm
todo: restore from DB on open
todo: separate thread for polling loop, update db loop, and local socket connection

Fri 26/6/2020
- Added DB updates when file/directory is removed or changed
- Changed sqlQueue to work more efficiently by not attempting to add entire fileIndex/dirIndex map contents each time. SQL insert/delete/update queries only queued on initial add/removal/update.

Sun 28/6/2020
- Researched C++ multithreading - std::thread and std::jthread
    - How to request a thread to stop with jthread: https://medium.com/@vgasparyan1995/a-new-thread-in-c-20-jthread-ebd121ae8906 (C++20)
        - jthread not supported in latest stable Debian g++ - full C++20 features not yet available, similarly cannot use std::osyncstream to sync output stream between threads. Only a few experimental features of c++20 are available via flag -std=c++2a.
    - std::mutex is required to lock/unlock shared data between threads, including cout to avoid garbled output. For processes that naturally come to an end, std::lock_guard is preferable - this automatically locks then unlocks when function is complete. mutex::lock() is required for our infinitely looping polling/DB threads.
    - As our threads will be infinite loops, running for the duration of the program, use an "std::atomic<bool> stopFlag" as the thread loop condition as this is threadsafe. This atomic bool can then be safely set from outside the threads when we want to close down the thread/loop.
    - test/thread-test.cpp created to test multi-threading and above concepts

Mon 29/6/2020
- Reading C++ Concurrency in Action, PRACTICAL MULTITHREADING by ANTHONY WILLIAMS
    - Considerations from p304:
        - Which data needs to be protected from concurrent access?
        - How do you ensure that the data is protected?
        - Where in the code could other threads be at this time?
        - Which mutexes does this thread hold?
        - Which mutexes might other threads hold?
        - Are there any ordering requirements between the operations done in this thread and those done in another? How are those requirements enforced?
        - Is the data loaded by this thread still valid? Could it have been modified by other threads?
        - If you assume that another thread could be modifying the data, what would that mean and how could you ensure that this never happens?
- Multi-threading:
    - Implemented the Watch::scanFileChange() and Watch::execQueuedSQL loop in a separate thread run from enclone class - see Watch::execThread() for loop
    - Socket now runs in a separate thread also, however significant work still required to test/check how socket works
    - Threads are terminated by setting std::atomic_bool flag in enclone class
    - Deleted copy constructors from Watch and Socket class - these classes should not be copied. 
        - Do not call a new thread on a class object as the class object is copied by default, and mutexes are unable to be copied. 
        - Call instead on a pointer to an entry function of an existing object i.e. std::thread t(&foo::bar, &f) and not std::thread t5(foo)
- todo: ensure correct mutexes and locks are in place - wait until further classes are written and have a better understanding of what resources will be shared
- todo: exception handling for file operations required?
- todo: does DB update want to be in the same thread as file system change? possibly not, in any case this wants to be more infrequent than filesystem polling - use global define/vars/config to set update times
- todo: start a basic upload to AWS S3 of watched files

Tue 30/6/2020
- Downloaded AWS C++ SDK and read through code, setup S3 bucket to test uploads
- Read AWS SDK documentation - https://docs.aws.amazon.com/sdk-for-cpp/v1/developer-guide/welcome.html
- Read AWS S3 documentation

Wed 1/7/2020
- AWS S3 remote
    - Setup AWS CLI with correct credentials from AWS Educate/Vocareum (Account Details -> AWS CLI to get .aws/credentials file)
    - Built relevant parts of AWS SDK from source (s3)
    - Included AWS SDK in enclone, tested basic API call/connection and correct compilation with CMAKE
    - Added calls to S3 to list available buckets and list all objects within that bucket
        - todo: does AWS SDK want to be included as static or shared lib? BUILD_SHARED_LIBS CMAKE var
        - todo: make S3 calls threaded so they are non-blocking
        - todo: design generic remote interface/class structure/methods i.e. upload()
- Started to design a flat encrypted file structure for remote locations
    - Weakness of rclone is identical filenames encrypt to identical filenames on remote and directory structure is retained
    - Potential solution is filename of encrypted file on remote is hash of original unencrypted file. Index contains mapping between original filepath and hash
        - All encrypted files are uploaded in a flat directory structure, and structure is restored from index on restore from remote
        - File hashes are already required to ensure integrity after upload/download so hashing is already in place
        - Possible weakness is if you lose the index, you lose the directory structure and filenames - however index can also be encrypted and uploaded to remote. How expensive to keep encrypting/uploading index when modified? Should be small overhead.
            - Known structure of index could pose a weakness for some encryption algorithms e.g. some block ciphers not using a Feedback Mode - can be avoided with appropriate encryption algos

Thur 2/7/2020
- Designed generic Queue class for a FIFO queue of objects to upload/delete on remote storage, using std::deque (double ended queue) for efficient addition and removal on both ends
- Amended S3.h to include generic Queue object, S3.h to run in separate thread, regularly uploading and deleting objects from the queue on the remote